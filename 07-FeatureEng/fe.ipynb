{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/esnt/Data/refs/heads/main/Text/gc_descriptions.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# sms_url = 'https://raw.githubusercontent.com/esnt/Data/refs/heads/main/CleanData/SMSSpamCollection'\n",
    "# df = pd.read_csv(sms_url, sep='\\t', header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['description'].apply(len)\n",
    "df['n_punct'] = df['description'].apply(lambda x: sum([1 for char in x if char in '.,;:!?']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df['description']\n",
    "tf = TfidfVectorizer(stop_words='english', min_df=20, max_df=0.5)\n",
    "X = tf.fit_transform(documents)\n",
    "vocab = tf.get_feature_names_out()\n",
    "tfidf_matrix = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.toarray(), columns=vocab).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_n = 10  \n",
    "word_importance = np.mean(tfidf_matrix, axis=0)  # Average TF-IDF scores across docs\n",
    "top_indices = np.argsort(word_importance)[-top_n:]  # Get indices of top words\n",
    "\n",
    "# Subset TF-IDF matrix and feature names\n",
    "n_docs = 50\n",
    "tfidf_matrix_small = tfidf_matrix[0:50, top_indices]\n",
    "top_feature_names = vocab[top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create heatmap for the selected words\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(tfidf_matrix_small, annot=True, xticklabels=top_feature_names, \n",
    "             yticklabels='', cmap='Blues')\n",
    "plt.title(\"TF-IDF Scores Heatmap (Top Words Only)\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Documents\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## probability need to install wordcloud\n",
    "## conda install -c conda-forge wordcloud\n",
    "## or\n",
    "## pip install wordcloud\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Combine all TF-IDF scores across documents\n",
    "word_weights = np.sum(tfidf_matrix, axis=0)\n",
    "word_dict = dict(zip(vocab, word_weights))\n",
    "\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_dict)\n",
    "\n",
    "# Display word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud of TF-IDF Weights\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=top_feature_names, y=word_importance[top_indices]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## conda install spacy\n",
    "## python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = np.array([nlp(word).vector for word in vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_vectors = pca.fit_transform(word_vectors)\n",
    "\n",
    "# Create DataFrame for easy plotting\n",
    "pca_df = pd.DataFrame(reduced_vectors, columns=[\"PCA1\", \"PCA2\"])\n",
    "pca_df[\"Word\"] = vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(pca_df, x='PCA1', y='PCA2', text='Word')\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(title=\"Phrase Embeddings Visualized with PCA\")\n",
    "fig.update_layout(width=800, height=800)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "phrase_vectors = []\n",
    "for phrase in documents:\n",
    "    doc = nlp(phrase)  # Process phrase using spaCy\n",
    "    vector = doc.vector  # Extract the phrase's vector representation (average of word vectors)\n",
    "    phrase_vectors.append(vector)\n",
    "\n",
    "# Convert to NumPy array\n",
    "phrase_vectors = np.array(phrase_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "reduced_vectors = pca.fit_transform(phrase_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_df = pd.DataFrame(reduced_vectors, columns=[\"PCA1\", \"PCA2\"])\n",
    "phrase_df[\"Phrase\"] = documents\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.scatter(phrase_df.sample(15), x='PCA1', y='PCA2', text='Phrase')\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(title=\"Phrase Embeddings Visualized with PCA\")\n",
    "# increase fig size\n",
    "fig.update_layout(width=1000, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shared",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
